{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "import cv2\n",
    "import math\n",
    "import pywt\n",
    "from src.srgan import Generator\n",
    "from src.data import SuperResolutionImageDataset\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PSNR Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psnr(hr,sr):\n",
    "  mse = np.mean((hr-sr)**2)\n",
    "  max = 255.0\n",
    "  psnr = 10*math.log10(max**2/mse)\n",
    "  return psnr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SSIM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Histogram Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downgrade_step(img,downgrade):\n",
    "  rows,cols,chan = img.shape\n",
    "  if rows%downgrade != 0 or cols%downgrade!=0 or (not isinstance(downgrade,int)):\n",
    "    print('Not a valid degradation!')\n",
    "    return None;\n",
    "\n",
    "  new_rows = int(rows/downgrade)\n",
    "  new_cols = int(cols/downgrade)\n",
    "\n",
    "  new_img = np.zeros(img.shape,dtype=int)\n",
    "\n",
    "  for c in range(chan):\n",
    "    new_img[:,:,c] = join_blocks(skimage.util.view_as_blocks(img[:,:,c],(downgrade,downgrade)))\n",
    "\n",
    "\n",
    "  return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_histogram(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    n_channels = hsv.shape[2]\n",
    "    channels = list(range(n_channels))\n",
    "    sizes = [256,]*n_channels\n",
    "    ranges = [0, 255]*n_channels\n",
    "    hist = cv2.calcHist(hsv, channels, None, sizes, ranges)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texture_histogram(img):\n",
    "    r,g,b = cv2.split(img)\n",
    "    approx = []\n",
    "    horiz = []\n",
    "    vert = []\n",
    "    for x in [b,g,r]:\n",
    "        cA, (cH, cV, _) = pywt.dwt2(x, 'haar')\n",
    "        approx.append(cA)\n",
    "        horiz.append(cH)\n",
    "        vert.append(cV)\n",
    "    img_approx = cv2.merge(approx)\n",
    "    img_horiz = cv2.merge(horiz)\n",
    "    img_vert = cv2.merge(vert)\n",
    "    # Step 5: assign weights to approx, horiz, and vert\n",
    "    new_img = cv2.addWeighted(img_approx, 0.75, img_horiz, 0.25, 0.0)\n",
    "    new_img = cv2.addWeighted(new_img, 0.8, img_vert, 0.2, 0.0)\n",
    "    return get_color_histogram(new_img.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(histA,histB):\n",
    "    histA = histA.flatten()\n",
    "    histA = histA/(sum(histA))\n",
    "    histB = histB.flatten()\n",
    "    histB = histB/(sum(histB))\n",
    "    denominator = min(np.sum(histA),np.sum(histB))\n",
    "    numerator = 0\n",
    "    for i in range(0,8*8*8):\n",
    "        minimum = histA[i] if histA[i] < histB[i] else histB[i]\n",
    "        numerator = numerator+minimum\n",
    "    return 1-numerator/denominator\n",
    "\n",
    "def get_chi_distance(histA,histB):\n",
    "    histA = histA.flatten()\n",
    "    histA = histA/(sum(histA))\n",
    "    histB = histB.flatten()\n",
    "    histB = histB/(sum(histB))\n",
    "    dist = 0.0\n",
    "    for i in range(0,8*8*8):\n",
    "        denom = histA[i]+histB[i]\n",
    "        if denom != 0:\n",
    "            dist = dist + np.square((histA[i]-histB[i]))/(histA[i]+histB[i])\n",
    "    return dist*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_pwh(hr,sr,n_bins):\n",
    "  new_shape = tuple(t//n_bins for t in hr.shape[:2])\n",
    "  hr_blocks = skimage.util.view_as_blocks(hr,(new_shape[0],new_shape[1],3))\n",
    "  sr_blocks = skimage.util.view_as_blocks(sr,(new_shape[0],new_shape[1],3))\n",
    "\n",
    "  distances_list_color = []\n",
    "  distances_list_texture = []\n",
    "  distances_list = []\n",
    "\n",
    "  for i in range(hr_blocks.shape[0]):\n",
    "    for j in range(hr_blocks.shape[1]):\n",
    "      sub_img_hr = hr_blocks[i,j,0,:,:]\n",
    "      sub_img_sr = sr_blocks[i,j,0,:,:]\n",
    "      hist_sub_hr = get_color_histogram(sub_img_hr)\n",
    "      texture_hist_sub_hr = get_texture_histogram(sub_img_hr)\n",
    "      hist_sub_sr = get_color_histogram(sub_img_sr)\n",
    "      texture_hist_sub_sr = get_texture_histogram(sub_img_sr)\n",
    "\n",
    "\n",
    "      distances_list_color.append(get_chi_distance(hist_sub_hr,hist_sub_sr))\n",
    "      distances_list_texture.append(get_chi_distance(texture_hist_sub_hr,texture_hist_sub_sr))\n",
    "      distances_list.append(get_chi_distance(hist_sub_hr,hist_sub_sr)*0.5+get_chi_distance(texture_hist_sub_hr,texture_hist_sub_sr)*0.5)\n",
    "\n",
    "  color_distance = sum(distances_list_color)/len(distances_list_color)\n",
    "  texture_distance = sum(distances_list_texture)/len(distances_list_texture)\n",
    "  distance = sum(distances_list)/len(distances_list)\n",
    "  return [color_distance,texture_distance,distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_pwh2(hr,sr,n_bins):\n",
    "  distances_list_color = []\n",
    "  distances_list_texture = []\n",
    "  distances_list = []\n",
    "\n",
    "  hist_hr = get_color_histogram(hr)\n",
    "  texture_hist_hr = get_texture_histogram(hr)\n",
    "  hist_sr = get_color_histogram(sr)\n",
    "  texture_hist_sr = get_texture_histogram(sr)\n",
    "\n",
    "  distances_list_color.append(get_chi_distance(hist_hr,hist_sr))\n",
    "  distances_list_texture.append(get_chi_distance(texture_hist_hr,texture_hist_sr))\n",
    "  distances_list.append(get_chi_distance(hist_hr,hist_sr)*0.5+get_chi_distance(texture_hist_hr,texture_hist_sr)*0.5)\n",
    "\n",
    "  color_distance = sum(distances_list_color)/len(distances_list_color)\n",
    "  texture_distance = sum(distances_list_texture)/len(distances_list_texture)\n",
    "  distance = sum(distances_list)/len(distances_list)\n",
    "  return [color_distance,texture_distance,distance]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Parameters\n",
    "data_path = \"./data/Renders/\"\n",
    "r = 4\n",
    "n_channels = 3\n",
    "B = 1\n",
    "batch_size_train = 128\n",
    "batch_size_validation = 128\n",
    "workers = 1\n",
    "seed = 1317\n",
    "train_test_val_split = [.7, .15, .15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_size = (128,128)\n",
    "lr_size = (hr_size[0]//r, hr_size[1]//r)\n",
    "hr_dimension = (*hr_size,n_channels)\n",
    "lr_dimension = (*lr_size,n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SuperResolutionImageDataset(\n",
    "    root = data_path,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(hr_size),\n",
    "    ]),\n",
    "    target_transform = transforms.Compose([\n",
    "        # transforms.GaussianBlur(3,1),\n",
    "        transforms.Resize(lr_size),\n",
    "    ])\n",
    ")\n",
    "\n",
    "random_generator = torch.Generator().manual_seed(seed)\n",
    "train_dataset, test_dataset, validation_dataset = torch.utils.data.random_split(dataset,train_test_val_split,random_generator)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size = batch_size_validation,\n",
    "    shuffle = True,\n",
    "    num_workers = workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(lr_dimension,B)\n",
    "netG.to(device)\n",
    "gen_load = torch.load('/Users/julionevado/Documents/Personal/SRGAN/checkpoints_perc_disc/generator')\n",
    "netG.load_state_dict(gen_load['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_lr = []\n",
    "img_list_hr = []\n",
    "\n",
    "for i,data in enumerate(validation_dataloader,0):\n",
    "    for batch_element in range(data[\"lr_sample\"].shape[0]):\n",
    "        img_list_lr.append(data[\"lr_sample\"][batch_element,:,:,:])\n",
    "    for batch_element in range(data[\"hr_sample\"].shape[0]):\n",
    "        img_list_hr.append(data[\"hr_sample\"][batch_element,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://discuss.pytorch.org/t/simple-way-to-inverse-transform-normalization/4821/2\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "    \n",
    "unorm = UnNormalize(mean = [0.5,0.5,0.5],\n",
    "            std = [0.5,0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdist_list = []\n",
    "tdist_list = []\n",
    "dist_list = []\n",
    "psnr_list = []\n",
    "for iter in range(len(img_list_hr)):\n",
    "    hr = unorm(img_list_hr[iter].to(device).unsqueeze(0)).cpu().numpy().transpose(2,3,1,0).squeeze(3)\n",
    "    sr = unorm(netG(img_list_lr[iter].to(device).unsqueeze(0)).detach()).cpu().numpy().transpose(2,3,1,0).squeeze(3)\n",
    "    cdist, tdist, dist = get_similarity_pwh2(hr,sr,16)\n",
    "    cdist_list.append(cdist)\n",
    "    tdist_list.append(tdist)\n",
    "    dist_list.append(dist)\n",
    "    psnr_list.append(compute_psnr(hr,sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mean = lambda l: sum(l)/len(l)\n",
    "print(list_mean(cdist_list))\n",
    "print(list_mean(tdist_list))\n",
    "print(list_mean(dist_list))\n",
    "print(list_mean(psnr_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(lr_dimension,B)\n",
    "netG.to(device)\n",
    "gen_load = torch.load('/Users/julionevado/Documents/Personal/SRGAN/checkpoints_perc_disc/generator')\n",
    "netG.load_state_dict(gen_load['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    hr = img_list_hr[i]\n",
    "    lr = img_list_lr[i]\n",
    "    Image.fromarray((unorm(hr.to(device).unsqueeze(0)).cpu().numpy().transpose(2,3,1,0).squeeze(3)*255).astype(np.uint8)).save(f'memory_images/ex{i+1}_hr.png')\n",
    "    Image.fromarray((unorm(lr.to(device).unsqueeze(0)).cpu().numpy().transpose(2,3,1,0).squeeze(3)*255).astype(np.uint8)).save(f'memory_images/ex{i+1}_lr.png')\n",
    "    Image.fromarray((unorm(netG(lr.to(device).unsqueeze(0)).detach()).cpu().numpy().transpose(2,3,1,0).squeeze(3)*255).astype(np.uint8)).save(f'memory_images/ex{i+1}_sr_perc_disc.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = cv2.imread('/Users/julionevado/Documents/Personal/SRGAN/memory_images/ex1_hr.png')\n",
    "sr = cv2.imread('/Users/julionevado/Documents/Personal/SRGAN/memory_images/ex1_sr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_list = []\n",
    "for i in [2,4,8,16]:\n",
    "  try:\n",
    "    distance_list.append((i,get_similarity_pwh(downgrade_step(hr,i).astype('uint8'),sr,8)))\n",
    "  except:\n",
    "    distance_list.append((i,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srgan_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
